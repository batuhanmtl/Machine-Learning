{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# VALIDATION AND CROSS VALIDATION"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<b> Measuring the model success again on the data used to develop the model may not give us reliable results. We have already found the model using this data. The success of a model is measured by the success of its predictions using data it has never seen before. So where do we find this new data?\n",
    "The general practice is to divide the data we have into two and test the model we developed with the second one while developing the model with the first one. These two models are called the learning set (traning set) and the validation set (test set). Although it is not a general rule, 70% or 80% of the main data is 20% or 30% of the learning cluster is called the validation cluster. For a healthy model development, the learning and validation clusters must be randomly divided.</b>\n",
    "\n",
    "<b>Python sklearn module has train_test_split function which is used to split data into learning and validation clusters.</b>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "\n",
    "bostondf = pd.read_csv('Boston.csv')\n",
    "lstat = bostondf[['lstat']].values\n",
    "medv = bostondf['medv'].values\n",
    "\n",
    "X_train , X_test ,Y_train , Y_test =train_test_split(lstat,medv,test_size=0.2,random_state=123)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<b>X_train and Y_train represent the dependent and non-dependent variables that will be used to develop the model, and X_test and Y_test to test the model. Test_size specifies the ratio of the data to be reserved for validation (test) and takes the value 0.25 by default. Random_state is used to generate random numbers.</b>\n",
    "\n",
    "<b>For example, if the data set we have includes the data for the years 2000 and 2010, we want the data for all years to be distributed to the development and test sets at the same rate (for example, 80% and 20%). In this case, we need to specify the column showing the years instead of y.</b>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "6.494118435984956"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train,Y_train)\n",
    "Y_estimate = model.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(Y_test,Y_estimate))\n",
    "rmse"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "0.4902618098232453"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RSS = sum((Y_test - Y_estimate)**2)\n",
    "TSS = sum((Y_test - np.mean(Y_test))**2)\n",
    "R2 = 1 - RSS/TSS\n",
    "R2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "0.48516442792147785"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = len(Y_test)\n",
    "d = X_test.shape[1]\n",
    "adj_R2 = 1 - (RSS/(n-d-1))/(TSS / (n-1))\n",
    "adj_R2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<b> As can be seen, when we divide the data set into learning and validation sets, the RMSE increases to 6.494, while the $R^{2}$ and adjusted $R^{2}$ values decrease to 0.49 and 0.485. </b>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- <b>K-FOLD CROSS VALIDATION</b>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<b>For cross validation in Python, we can use the cross_val_score() function in the sklearn.model_selection module. This function accepts the model to be used (linear regression), dependent and non-dependent variable sets, and the number of pieces (cv) to which the data set will be split as arguments. Since the performance indicator (_score) is $R^{2}$, this function generates a string containing $R^{2}$ values equal to the k value, that is, the number of trials performed. </b>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.31784807, 0.5406078 , 0.07608699, 0.42423767, 0.1267687 ])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "cross_R2 = cross_val_score(model,lstat,medv,cv=5)\n",
    "cross_R2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "0.29710984600668633"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_R2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<b>As can be seen, the average $R^{2}$ value is 0.55 when we use the whole data set, 0.49 when we distinguish between learning and validation once, and 0.297 when we perform 5-fold cross validation.</b>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}