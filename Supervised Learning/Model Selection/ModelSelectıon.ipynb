{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# MODEL SELECTION"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1) Ridge Regression\n",
    "\n",
    "# $RSS + \\alpha \\sum_{j}^{d}\\hat{\\beta }_{j}^{2}$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<b>By adding a new term to the RSS term in Ridge Regression, it aims to reduce the coefficients of the variables that do not contribute to the correlation. While determining the coefficients in the Ridge regression, the above term is tried to be minimized instead of RSS.</b>\n",
    "\n",
    "<b>You can think of the alpha in front of the total as a correction coefficient. This coefficient is determined by the user. With the help of this term, the beta coefficients are reduced. If the alpha value to be used is equal to zero, the result will be the same as the sum of the smallest squares. On the other hand, as the alpha value gets larger, the beta coefficients approach zero. For this reason, the selection of the alpha value that will give the best result is very important. For the alpha value that will give the most successful result, cross validation methods can be used.</b>\n",
    "\n",
    "<b>Ridge() function from the sklearn.linear_model module is used for Ridge regression in Python. In this function, we specify the value of $\\alpha $ with alpha argument. Also, by using the normalize=True argument, it is ensured that all variables are normalized and brought to the same scale.</b>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "bostondf = pd.read_csv('Boston.csv')\n",
    "\n",
    "X = bostondf.drop('medv',axis=1)\n",
    "y = bostondf['medv']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\batuhan\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.7315784496375433"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge_model = Ridge(alpha=0.1,normalize=True)\n",
    "ridge_model.fit(X,y)\n",
    "ridge_model.score(X,y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "26.437529739426683"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_model.intercept_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "array([-8.39972182e-02,  3.01457989e-02, -4.51085108e-02,  2.91942377e+00,\n       -1.07499818e+01,  4.02329138e+00, -4.56047447e-03, -1.03180235e+00,\n        1.30441043e-01, -4.95778250e-03, -8.32529832e-01,  8.96754880e-03,\n       -4.57771753e-01])"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_model.coef_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}